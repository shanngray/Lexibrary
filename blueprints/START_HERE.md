# Lexibrarian — Start Here

> **Note:** `blueprints/` is a hand-maintained pseudo-lexibrary for agents building Lexibrarian itself — not to be confused with the `.lexibrary/` output that Lexibrarian produces for other projects.

## Project Topology

```
src/lexibrarian/
├── __init__.py
├── __main__.py
├── cli.py                       ← Typer CLI entry point (lexi command)
├── exceptions.py                ← LexibraryNotFoundError
├── artifacts/                   ← Pydantic 2 models + parser/serializer/writer for all artifact types
│   ├── __init__.py
│   ├── aindex.py                ← AIndexFile + AIndexEntry models
│   ├── aindex_parser.py         ← Parse .aindex files from disk
│   ├── aindex_serializer.py     ← Serialize AIndexFile to .aindex text
│   ├── concept.py               ← ConceptFile model
│   ├── design_file.py           ← DesignFile model
│   ├── guardrail.py             ← GuardrailThread model
│   └── writer.py                ← write_artifact() — persists any artifact to disk
├── ast_parser/                  ← Tree-sitter interface extraction: models, registry, language parsers, canonical renderer
│   ├── __init__.py              ← Public API: parse_interface(), hash_interface(), compute_hashes()
│   ├── models.py                ← Pydantic 2 models: InterfaceSkeleton, ClassSig, FunctionSig, ConstantSig, ParameterSig
│   ├── registry.py              ← GrammarInfo + GRAMMAR_MAP; lazy-load/cache tree-sitter Language + Parser
│   ├── skeleton_render.py       ← render_skeleton() — deterministic canonical text for hashing
│   ├── python_parser.py         ← extract_interface() for .py / .pyi
│   ├── typescript_parser.py     ← extract_interface() for .ts / .tsx
│   └── javascript_parser.py     ← extract_interface() for .js / .jsx
├── baml_client/                 ← AUTO-GENERATED by BAML — do not edit; contents omitted from this tree
├── config/                      ← Config schema (Pydantic 2) + loader + defaults
│   ├── __init__.py
│   ├── defaults.py              ← Default config template written on lexi init
│   ├── loader.py                ← Two-tier YAML loader (project + user overrides)
│   └── schema.py                ← LexibraryConfig Pydantic model
├── crawler/                     ← Bottom-up crawl orchestration + change detection (LLM-based, partially broken)
│   ├── __init__.py
│   ├── change_detector.py       ← SHA-256 + LLM-based change detection
│   ├── discovery.py             ← Filesystem traversal + file enumeration
│   ├── engine.py                ← full_crawl() orchestrator (partially broken — see blueprints)
│   └── file_reader.py           ← Read source files for crawl input
├── daemon/                      ← Watchdog file watcher + debouncer + periodic sweep
│   ├── __init__.py
│   ├── debouncer.py             ← Coalesce rapid file-change events
│   ├── scheduler.py             ← Periodic sweep scheduler
│   ├── service.py               ← DaemonService — top-level watchdog coordinator
│   └── watcher.py               ← watchdog filesystem event handler
├── ignore/                      ← pathspec-based ignore pattern matching
│   ├── __init__.py
│   ├── gitignore.py             ← Load + parse .gitignore files
│   ├── matcher.py               ← IgnoreMatcher combining .gitignore + config patterns
│   └── patterns.py              ← Built-in default ignore patterns
├── indexer/                     ← Structural .aindex generation (no LLM): generator + orchestrator
│   ├── __init__.py
│   ├── generator.py             ← generate_aindex() — builds AIndexFile from a directory
│   └── orchestrator.py          ← lexi index entry point; drives generator → serializer → writer
├── init/                        ← lexi init scaffolding (.lexibrary/ skeleton)
│   ├── __init__.py
│   └── scaffolder.py            ← create_lexibrary_skeleton()
├── llm/                         ← BAML client wrapper + rate limiter + factory
│   ├── __init__.py
│   ├── factory.py               ← create_llm_service() factory
│   ├── rate_limiter.py          ← Token-bucket rate limiter
│   └── service.py               ← LLMService wrapping BAML async client
├── tokenizer/                   ← Pluggable token counting backends
│   ├── __init__.py
│   ├── anthropic_counter.py     ← Anthropic token counting backend
│   ├── approximate.py           ← Character-ratio approximate backend
│   ├── base.py                  ← TokenCounter protocol
│   ├── factory.py               ← Backend selection factory
│   └── tiktoken_counter.py      ← tiktoken (OpenAI) backend
└── utils/                       ← Hashing, language detection, logging, paths, root
    ├── __init__.py
    ├── hashing.py               ← hash_file() SHA-256 helper
    ├── languages.py             ← detect_language() by extension
    ├── logging.py               ← setup_logging() rich handler
    ├── paths.py                 ← Path helpers for .lexibrary/ layout
    └── root.py                  ← find_project_root() — walks up to locate .lexibrary/
```

## Package Map

| Package | Role |
| --- | --- |
| `artifacts` | Pydantic 2 models: `DesignFile`, `AIndexFile`, `ConceptFile`, `GuardrailThread`; plus `aindex_parser`, `aindex_serializer`, `writer` |
| `ast_parser` | Tree-sitter interface extraction: `parse_interface`, `compute_hashes`, `hash_interface`; `InterfaceSkeleton` model; Python / TypeScript / JavaScript parsers; `render_skeleton` canonical renderer |
| `config` | `LexibraryConfig` schema, two-tier YAML loader, default config template |
| `crawler` | `full_crawl()` orchestrator; discovery, file reading, change detection (LLM-based; partially broken — see crawler/engine.md) |
| `daemon` | `DaemonService` — watchdog + debounce + periodic sweep |
| `ignore` | `IgnoreMatcher` combining `.gitignore` + config patterns via pathspec |
| `indexer` | Structural `.aindex` pipeline: `generate_aindex` → `serialize_aindex` → `write_artifact`; no LLM |
| `init` | `create_lexibrary_skeleton()` — creates `.lexibrary/` on `lexi init` |
| `llm` | `LLMService` wrapping BAML client; `RateLimiter`; `create_llm_service()` factory |
| `tokenizer` | `TokenCounter` protocol; tiktoken / anthropic / approximate backends |
| `utils` | `hash_file`, `detect_language`, `setup_logging`, `find_project_root`, path helpers |

## Navigation by Intent

| Task | Read first |
| --- | --- |
| Add / modify a CLI command | `blueprints/src/lexibrarian/cli.md` |
| Add a language parser or modify AST extraction | `blueprints/src/lexibrarian/ast_parser/` |
| Change config keys or defaults | `blueprints/src/lexibrarian/config/` |
| Modify crawl logic (LLM-based) | `blueprints/src/lexibrarian/crawler/engine.md` |
| Modify structural indexing (no LLM) | `blueprints/src/lexibrarian/indexer/` |
| Change ignore patterns | `blueprints/src/lexibrarian/ignore/` |
| Add / modify LLM prompts | `baml_src/` (source-of-truth for prompts) |
| Change artifact data models | `blueprints/src/lexibrarian/artifacts/` |
| Change `.aindex` file format | `blueprints/src/lexibrarian/artifacts/aindex_serializer.md` + `aindex_parser.md` |
| Modify daemon behavior | `blueprints/src/lexibrarian/daemon/` |
| Add a tokenizer backend | `blueprints/src/lexibrarian/tokenizer/` |
| Change `lexi init` scaffolding | `blueprints/src/lexibrarian/init/scaffolder.md` |
| Change path utilities | `blueprints/src/lexibrarian/utils/paths.md` |
| Raise / handle project-not-found | `blueprints/src/lexibrarian/exceptions.md` |

## Key Constraints

- `from __future__ import annotations` in **every** module
- pathspec pattern name is `"gitignore"` — NOT `"gitwildmatch"`
- Config: YAML via PyYAML, validated with Pydantic 2
- Output: `rich.console.Console` — no bare `print()`
- `baml_client/` is auto-generated — never edit it directly
- `crawler/engine.py` is partially broken: references `config.output`, `FileEntry`/`DirEntry`/`IandexData` types not yet defined — use `indexer/orchestrator.py` for `lexi index` instead

## Navigation Protocol

Before editing a file, read its design file in `blueprints/src/`. Keep design files updated when you change source files — the source is truth, the design file is the explanation.
